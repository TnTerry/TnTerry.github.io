---
title: '旋转位置编码 (RoPE)'
date: 2025-03-30
excerpt: |
  RoPE原理与实现
permalink: /posts/2025/03/RoPE/
tags:
  - 技术
  - LLM
  - Embedding
  - RoPE
---

[旋转位置编码 (Rotary Position Embedding, RoPE)](https://arxiv.org/pdf/2104.09864) 是一种用于增强Transformer模型中位置编码的技术。目前，主流的大语言模型大多采用RoPE作为位置编码方法。

# RoPE的原理

## 基础概念

输入序列是由 \\( N \\) 个token组成的序列，其中 \\( w_i \\) 是第 \\( i \\) 个token：

$$
\mathbb{S}_N = \{w_i \}_{i=1}^N \in \mathbb{R}^{N \times d}
$$

我们将输入序列的每个token嵌入到一个 \\( d \\) 维的向量空间中，我们可以得到embedding序列：

$$
\mathbb{E}_N = \{x_i \}_{i=1}^N \in \mathbb{R}^{N \times d}
$$

其中 \\(x_i \\) 是第 \\( i \\) 个token的嵌入向量，且 \\( x_i \in \mathbb{R}^d \\) 是 \\( d \\) 维的向量。

在计算self-attention之前，我们将位置信息与embedding进行融合，并将它们分别转化为 \\( q \\) , \\( k \\) 和 \\( v \\) 向量。**所有位置编码，都是在试图构造一个合适的函数** \\( f(q, k, v) \\)

$$
\begin{aligned}
q_m &= f_q(x_m, m) \\
k_n &= f_k(x_n, n) \\
v_n &= f_v(x_n, n)
\end{aligned}
$$

后续在计算self-attention时，我们会使用 \\( q \\) 和 \\( k \\) 来计算注意力权重，使用 \\( v \\) 来计算输出。

$$
\begin{aligned}
a_{m,n} = \frac{exp(\frac{q_m^\top k_n}{\sqrt{d}})}{\sum_{i=1}^N exp(\frac{q_m^\top k_i}{\sqrt{d}})} \\
o_{m,n} = \sum_{n=1}^N a_{m,n} v_n
\end{aligned}
$$

## 绝对位置编码

对于传统的绝对位置编码，常用的做法是将位置编码 \\( p \\) 直接加到embedding向量上。其中，位置编码 \\( p_i \in \mathbb{R}^d \\) 是一个 \\( d \\) 维的向量，表示第 \\( i \\) 个token的位置信息。

一种经典的计算绝对位置编码的方式为Sinusoidal函数：

$$
p_{i, j} = \begin{cases}
\sin(\frac{i}{10000^{\frac{2j}{d}}}) & \text{if } j = 2k \\
\cos(\frac{i}{10000^{\frac{2j}{d}}}) & \text{if } j = 2k + 1 
\end{cases}
$$

在此基础上，我们对叠加后的embedding向量进行线性变换，得到最终的 \\( q \\) , \\( k \\) 和 \\( v \\) 向量。因此，使用绝对位置编码时，我们构造的函数为：

$$
\begin{aligned}
f_{t:t \in \{q, k, v\}}(x_i, i) &:= W_{t:t \in \{q, k, v\}}(x_i, i)(x_i + p_i) \\
W_{t:t \in \{q, k, v\}} & \in \mathbb{R}^{d \times d}
\end{aligned}
$$

## RoPE

### 复数基本概念

对于复数 \\( z = a + bi \\) ， 我们可以将其看作为一个二维向量 \\( z = (a, b)^ \top \\) ， 其中 \\( a \\) 和 \\( b \\) 分别是实部和虚部。

对于两个复数 \\( z_1 = a_1 + b_1 i \\) 和 \\( z_2 = a_2 + b_2 i \\)，我们可以定义它们的乘法为：

$$
z_1 \cdot z_2 = (a_1 + b_1 i)
\cdot (a_2 + b_2 i) = (a_1 a_2 - b_1 b_2) + (a_1 b_2 + a_2 b_1)i
$$

可以进一步将其写成矩阵和向量相乘的形式，进而将复数的乘法看作向量 \\(z_2 \\)经过矩阵 \\( \begin{pmatrix} a_1 & -b_1 \\ b_1 & a_1 \end{pmatrix} \\) 的旋转变换：

$$
z_1 \cdot z_2 = \begin{pmatrix} a_1 & -b_1 \\ b_1 & a_1 \end{pmatrix} \begin{pmatrix} a_2 \\ b_2 \end{pmatrix}
= \begin{pmatrix} a_1 a_2 - b_1 b_2 \\ a_1 b_2 + a_2 b_1 \end{pmatrix}
$$

复数 \\( z \\) 的模长 \\( |z| = \sqrt{a^2 + b^2} \\) 是不变的，其辐角为 \\( \theta = \arctan(\frac{b}{a}) \\) 。因此，上述的矩阵 \\( \begin{pmatrix} a_1 & -b_1 \\ b_1 & a_1 \end{pmatrix} \\) 可以进一步写为：

$$
\begin{align*}
\begin{bmatrix}
a_1 & -b_1 \\
b_1 & a_1
\end{bmatrix}
&= \sqrt{a_1^2 + b_1^2}
\begin{bmatrix}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{bmatrix} \\
&= \| z_1 \| 
\begin{bmatrix}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{bmatrix} \\
&= \| z_1 \| \cdot I 
\begin{bmatrix}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{bmatrix} \\
&= 
\begin{bmatrix}
\| z_1 \| & 0 \\
0 & \| z_1 \|
\end{bmatrix}
\begin{bmatrix}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{bmatrix}.
\end{align*}
$$

因此，旋转矩阵 \\( R \\) 可以表示为：

$$
R = \begin{bmatrix}
\cos(\theta) & -\sin(\theta) \\ \sin(\theta) & \cos(\theta) \end{bmatrix}
$$

---

复数的欧拉公式：

$$
e^{i\theta} = \cos(\theta) + i\sin(\theta)
$$

